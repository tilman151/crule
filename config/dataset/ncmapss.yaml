# @package _global_
#
# empty stub to specify the dataset
# the finally used data is determined by the dataset-task combination

dataset: ncmapss
patience: 60

pretraining:
  trainer:
    max_epochs: 300
    log_every_n_steps: 1
    callbacks:
      - _target_: pytorch_lightning.callbacks.ModelCheckpoint
        monitor: val/loss
        mode: min
        save_top_k: 1

training:
  trainer:
    log_every_n_steps: 1
    max_epochs: 1200
